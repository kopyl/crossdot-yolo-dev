{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olehkopyl/.pyenv/versions/3.8.13/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:54: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NoSuchFile",
     "evalue": "[ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from ../models/yolov8m.onnx failed:Load model ../models/yolov8m.onnx failed. File doesn't exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchFile\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 269\u001b[0m\n\u001b[1;32m    266\u001b[0m model_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m../models/yolov8m.onnx\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m \u001b[39m# Initialize YOLOv7 object detector\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m yolov7_detector \u001b[39m=\u001b[39m YOLOv8(model_path, conf_thres\u001b[39m=\u001b[39;49m\u001b[39m0.3\u001b[39;49m, iou_thres\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m)\n\u001b[1;32m    271\u001b[0m img_url \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://live.staticflickr.com/13/19041780_d6fd803de0_3k.jpg\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    272\u001b[0m img \u001b[39m=\u001b[39m imread_from_url(img_url)\n",
      "Cell \u001b[0;32mIn[2], line 156\u001b[0m, in \u001b[0;36mYOLOv8.__init__\u001b[0;34m(self, path, conf_thres, iou_thres)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miou_threshold \u001b[39m=\u001b[39m iou_thres\n\u001b[1;32m    155\u001b[0m \u001b[39m# Initialize model\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minitialize_model(path)\n",
      "Cell \u001b[0;32mIn[2], line 162\u001b[0m, in \u001b[0;36mYOLOv8.initialize_model\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minitialize_model\u001b[39m(\u001b[39mself\u001b[39m, path):\n\u001b[0;32m--> 162\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession \u001b[39m=\u001b[39m onnxruntime\u001b[39m.\u001b[39;49mInferenceSession(path,\n\u001b[1;32m    163\u001b[0m                                                 providers\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mCUDAExecutionProvider\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    164\u001b[0m                                                            \u001b[39m'\u001b[39;49m\u001b[39mCPUExecutionProvider\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    165\u001b[0m     \u001b[39m# Get model info\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_input_details()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:347\u001b[0m, in \u001b[0;36mInferenceSession.__init__\u001b[0;34m(self, path_or_bytes, sess_options, providers, provider_options, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m disabled_optimizers \u001b[39m=\u001b[39m kwargs[\u001b[39m\"\u001b[39m\u001b[39mdisabled_optimizers\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mdisabled_optimizers\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwargs \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 347\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_inference_session(providers, provider_options, disabled_optimizers)\n\u001b[1;32m    348\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_fallback:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:384\u001b[0m, in \u001b[0;36mInferenceSession._create_inference_session\u001b[0;34m(self, providers, provider_options, disabled_optimizers)\u001b[0m\n\u001b[1;32m    382\u001b[0m session_options \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sess_options \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sess_options \u001b[39melse\u001b[39;00m C\u001b[39m.\u001b[39mget_default_session_options()\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model_path:\n\u001b[0;32m--> 384\u001b[0m     sess \u001b[39m=\u001b[39m C\u001b[39m.\u001b[39;49mInferenceSession(session_options, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model_path, \u001b[39mTrue\u001b[39;49;00m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_config_from_model)\n\u001b[1;32m    385\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     sess \u001b[39m=\u001b[39m C\u001b[39m.\u001b[39mInferenceSession(session_options, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model_bytes, \u001b[39mFalse\u001b[39;00m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_config_from_model)\n",
      "\u001b[0;31mNoSuchFile\u001b[0m: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from ../models/yolov8m.onnx failed:Load model ../models/yolov8m.onnx failed. File doesn't exist"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "\n",
    "class_names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "               'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "               'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "               'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "               'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
    "               'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase',\n",
    "               'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "# Create a list of colors for each class where each color is a tuple of 3 integer values\n",
    "rng = np.random.default_rng(3)\n",
    "colors = rng.uniform(0, 255, size=(len(class_names), 3))\n",
    "\n",
    "\n",
    "def nms(boxes, scores, iou_threshold):\n",
    "    # Sort by score\n",
    "    sorted_indices = np.argsort(scores)[::-1]\n",
    "\n",
    "    keep_boxes = []\n",
    "    while sorted_indices.size > 0:\n",
    "        # Pick the last box\n",
    "        box_id = sorted_indices[0]\n",
    "        keep_boxes.append(box_id)\n",
    "\n",
    "        # Compute IoU of the picked box with the rest\n",
    "        ious = compute_iou(boxes[box_id, :], boxes[sorted_indices[1:], :])\n",
    "\n",
    "        # Remove boxes with IoU over the threshold\n",
    "        keep_indices = np.where(ious < iou_threshold)[0]\n",
    "\n",
    "        # print(keep_indices.shape, sorted_indices.shape)\n",
    "        sorted_indices = sorted_indices[keep_indices + 1]\n",
    "\n",
    "    return keep_boxes\n",
    "\n",
    "\n",
    "def compute_iou(box, boxes):\n",
    "    # Compute xmin, ymin, xmax, ymax for both boxes\n",
    "    xmin = np.maximum(box[0], boxes[:, 0])\n",
    "    ymin = np.maximum(box[1], boxes[:, 1])\n",
    "    xmax = np.minimum(box[2], boxes[:, 2])\n",
    "    ymax = np.minimum(box[3], boxes[:, 3])\n",
    "\n",
    "    # Compute intersection area\n",
    "    intersection_area = np.maximum(0, xmax - xmin) * np.maximum(0, ymax - ymin)\n",
    "\n",
    "    # Compute union area\n",
    "    box_area = (box[2] - box[0]) * (box[3] - box[1])\n",
    "    boxes_area = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "    union_area = box_area + boxes_area - intersection_area\n",
    "\n",
    "    # Compute IoU\n",
    "    iou = intersection_area / union_area\n",
    "\n",
    "    return iou\n",
    "\n",
    "\n",
    "def xywh2xyxy(x):\n",
    "    # Convert bounding box (x, y, w, h) to bounding box (x1, y1, x2, y2)\n",
    "    y = np.copy(x)\n",
    "    y[..., 0] = x[..., 0] - x[..., 2] / 2\n",
    "    y[..., 1] = x[..., 1] - x[..., 3] / 2\n",
    "    y[..., 2] = x[..., 0] + x[..., 2] / 2\n",
    "    y[..., 3] = x[..., 1] + x[..., 3] / 2\n",
    "    return y\n",
    "\n",
    "\n",
    "def draw_detections(image, boxes, scores, class_ids, mask_alpha=0.3):\n",
    "    mask_img = image.copy()\n",
    "    det_img = image.copy()\n",
    "\n",
    "    img_height, img_width = image.shape[:2]\n",
    "    size = min([img_height, img_width]) * 0.0006\n",
    "    text_thickness = int(min([img_height, img_width]) * 0.001)\n",
    "\n",
    "    # Draw bounding boxes and labels of detections\n",
    "    for box, score, class_id in zip(boxes, scores, class_ids):\n",
    "        color = colors[class_id]\n",
    "\n",
    "        x1, y1, x2, y2 = box.astype(int)\n",
    "\n",
    "        # Draw rectangle\n",
    "        cv2.rectangle(det_img, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "        # Draw fill rectangle in mask image\n",
    "        cv2.rectangle(mask_img, (x1, y1), (x2, y2), color, -1)\n",
    "\n",
    "        label = class_names[class_id]\n",
    "        caption = f'{label} {int(score * 100)}%'\n",
    "        (tw, th), _ = cv2.getTextSize(text=caption, fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                      fontScale=size, thickness=text_thickness)\n",
    "        th = int(th * 1.2)\n",
    "\n",
    "        cv2.rectangle(det_img, (x1, y1),\n",
    "                      (x1 + tw, y1 - th), color, -1)\n",
    "        cv2.rectangle(mask_img, (x1, y1),\n",
    "                      (x1 + tw, y1 - th), color, -1)\n",
    "        cv2.putText(det_img, caption, (x1, y1),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, size, (255, 255, 255), text_thickness, cv2.LINE_AA)\n",
    "\n",
    "        cv2.putText(mask_img, caption, (x1, y1),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, size, (255, 255, 255), text_thickness, cv2.LINE_AA)\n",
    "\n",
    "    return cv2.addWeighted(mask_img, mask_alpha, det_img, 1 - mask_alpha, 0)\n",
    "\n",
    "\n",
    "def draw_comparison(img1, img2, name1, name2, fontsize=2.6, text_thickness=3):\n",
    "    (tw, th), _ = cv2.getTextSize(text=name1, fontFace=cv2.FONT_HERSHEY_DUPLEX,\n",
    "                                  fontScale=fontsize, thickness=text_thickness)\n",
    "    x1 = img1.shape[1] // 3\n",
    "    y1 = th\n",
    "    offset = th // 5\n",
    "    cv2.rectangle(img1, (x1 - offset * 2, y1 + offset),\n",
    "                  (x1 + tw + offset * 2, y1 - th - offset), (0, 115, 255), -1)\n",
    "    cv2.putText(img1, name1,\n",
    "                (x1, y1),\n",
    "                cv2.FONT_HERSHEY_DUPLEX, fontsize,\n",
    "                (255, 255, 255), text_thickness)\n",
    "\n",
    "\n",
    "    (tw, th), _ = cv2.getTextSize(text=name2, fontFace=cv2.FONT_HERSHEY_DUPLEX,\n",
    "                                  fontScale=fontsize, thickness=text_thickness)\n",
    "    x1 = img2.shape[1] // 3\n",
    "    y1 = th\n",
    "    offset = th // 5\n",
    "    cv2.rectangle(img2, (x1 - offset * 2, y1 + offset),\n",
    "                  (x1 + tw + offset * 2, y1 - th - offset), (94, 23, 235), -1)\n",
    "\n",
    "    cv2.putText(img2, name2,\n",
    "                (x1, y1),\n",
    "                cv2.FONT_HERSHEY_DUPLEX, fontsize,\n",
    "                (255, 255, 255), text_thickness)\n",
    "\n",
    "    combined_img = cv2.hconcat([img1, img2])\n",
    "    if combined_img.shape[1] > 3840:\n",
    "        combined_img = cv2.resize(combined_img, (3840, 2160))\n",
    "\n",
    "    return combined_img\n",
    "\n",
    "\n",
    "class YOLOv8:\n",
    "\n",
    "    def __init__(self, path, conf_thres=0.7, iou_thres=0.5):\n",
    "        self.conf_threshold = conf_thres\n",
    "        self.iou_threshold = iou_thres\n",
    "\n",
    "        # Initialize model\n",
    "        self.initialize_model(path)\n",
    "\n",
    "    def __call__(self, image):\n",
    "        return self.detect_objects(image)\n",
    "\n",
    "    def initialize_model(self, path):\n",
    "        self.session = onnxruntime.InferenceSession(path,\n",
    "                                                    providers=['CUDAExecutionProvider',\n",
    "                                                               'CPUExecutionProvider'])\n",
    "        # Get model info\n",
    "        self.get_input_details()\n",
    "        self.get_output_details()\n",
    "\n",
    "\n",
    "    def detect_objects(self, image):\n",
    "        input_tensor = self.prepare_input(image)\n",
    "\n",
    "        # Perform inference on the image\n",
    "        outputs = self.inference(input_tensor)\n",
    "\n",
    "        self.boxes, self.scores, self.class_ids = self.process_output(outputs)\n",
    "\n",
    "        return self.boxes, self.scores, self.class_ids\n",
    "\n",
    "    def prepare_input(self, image):\n",
    "        self.img_height, self.img_width = image.shape[:2]\n",
    "\n",
    "        input_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Resize input image\n",
    "        input_img = cv2.resize(input_img, (self.input_width, self.input_height))\n",
    "\n",
    "        # Scale input pixel values to 0 to 1\n",
    "        input_img = input_img / 255.0\n",
    "        input_img = input_img.transpose(2, 0, 1)\n",
    "        input_tensor = input_img[np.newaxis, :, :, :].astype(np.float32)\n",
    "\n",
    "        return input_tensor\n",
    "\n",
    "\n",
    "    def inference(self, input_tensor):\n",
    "        start = time.perf_counter()\n",
    "        outputs = self.session.run(self.output_names, {self.input_names[0]: input_tensor})\n",
    "\n",
    "        # print(f\"Inference time: {(time.perf_counter() - start)*1000:.2f} ms\")\n",
    "        return outputs\n",
    "\n",
    "    def process_output(self, output):\n",
    "        predictions = np.squeeze(output[0]).T\n",
    "\n",
    "        # Filter out object confidence scores below threshold\n",
    "        scores = np.max(predictions[:, 4:], axis=1)\n",
    "        predictions = predictions[scores > self.conf_threshold, :]\n",
    "        scores = scores[scores > self.conf_threshold]\n",
    "\n",
    "        if len(scores) == 0:\n",
    "            return [], [], []\n",
    "\n",
    "        # Get the class with the highest confidence\n",
    "        class_ids = np.argmax(predictions[:, 4:], axis=1)\n",
    "\n",
    "        # Get bounding boxes for each object\n",
    "        boxes = self.extract_boxes(predictions)\n",
    "\n",
    "        # Apply non-maxima suppression to suppress weak, overlapping bounding boxes\n",
    "        indices = nms(boxes, scores, self.iou_threshold)\n",
    "\n",
    "        return boxes[indices], scores[indices], class_ids[indices]\n",
    "\n",
    "    def extract_boxes(self, predictions):\n",
    "        # Extract boxes from predictions\n",
    "        boxes = predictions[:, :4]\n",
    "\n",
    "        # Scale boxes to original image dimensions\n",
    "        boxes = self.rescale_boxes(boxes)\n",
    "\n",
    "        # Convert boxes to xyxy format\n",
    "        boxes = xywh2xyxy(boxes)\n",
    "\n",
    "        return boxes\n",
    "\n",
    "    def rescale_boxes(self, boxes):\n",
    "\n",
    "        # Rescale boxes to original image dimensions\n",
    "        input_shape = np.array([self.input_width, self.input_height, self.input_width, self.input_height])\n",
    "        boxes = np.divide(boxes, input_shape, dtype=np.float32)\n",
    "        boxes *= np.array([self.img_width, self.img_height, self.img_width, self.img_height])\n",
    "        return boxes\n",
    "\n",
    "    def draw_detections(self, image, draw_scores=True, mask_alpha=0.4):\n",
    "\n",
    "        return draw_detections(image, self.boxes, self.scores,\n",
    "                               self.class_ids, mask_alpha)\n",
    "\n",
    "    def get_input_details(self):\n",
    "        model_inputs = self.session.get_inputs()\n",
    "        self.input_names = [model_inputs[i].name for i in range(len(model_inputs))]\n",
    "\n",
    "        self.input_shape = model_inputs[0].shape\n",
    "        self.input_height = self.input_shape[2]\n",
    "        self.input_width = self.input_shape[3]\n",
    "\n",
    "    def get_output_details(self):\n",
    "        model_outputs = self.session.get_outputs()\n",
    "        self.output_names = [model_outputs[i].name for i in range(len(model_outputs))]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from imread_from_url import imread_from_url\n",
    "\n",
    "    model_path = \"../models/yolov8m.onnx\"\n",
    "\n",
    "    # Initialize YOLOv7 object detector\n",
    "    yolov7_detector = YOLOv8(model_path, conf_thres=0.3, iou_thres=0.5)\n",
    "\n",
    "    img_url = \"https://live.staticflickr.com/13/19041780_d6fd803de0_3k.jpg\"\n",
    "    img = imread_from_url(img_url)\n",
    "\n",
    "    # Detect Objects\n",
    "    yolov7_detector(img)\n",
    "\n",
    "    # Draw detections\n",
    "    combined_img = yolov7_detector.draw_detections(img)\n",
    "    cv2.namedWindow(\"Output\", cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"Output\", combined_img)\n",
    "    cv2.waitKey(0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
